{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3521043,"sourceType":"datasetVersion","datasetId":2118574}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Import libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport random\nimport itertools\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten, Dense, Activation\nfrom tensorflow .keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import recall_score, precision_score, confusion_matrix, f1_score, cohen_kappa_score, balanced_accuracy_score, accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2 Read Data","metadata":{}},{"cell_type":"markdown","source":"## A- convert files to lists","metadata":{}},{"cell_type":"code","source":"Path_data = '/kaggle/input/diabetic-retinopathy-dataset'\ndata = os.listdir(Path_data)\nHealthy = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Healthy')\nMild = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Mild DR')\nModerate = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Moderate DR')\nProliferate = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Proliferate DR')\nSevere = os.listdir('/kaggle/input/diabetic-retinopathy-dataset/Severe DR')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"classes names :\", (data), \"\\n______________________________\\n\")\nprint(\"Number of classes :\", len(data), \"\\n______________________________\\n\")\nprint(\"Number of Healty images :\", len(Healthy), \"\\n______________________________\\n\")\nprint(\"Number of Mild images :\", len(Mild),  \"\\n______________________________\\n\")\nprint(\"Number of Moderate images :\", len(Moderate),  \"\\n______________________________\\n\")\nprint(\"Number of Proliferate images :\", len(Proliferate),  \"\\n______________________________\\n\")\nprint(\"Number of severe images :\", len(Severe),  \"\\n______________________________\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## B- Create a dataframe","metadata":{}},{"cell_type":"code","source":"# Get Paths\n\nPath_data = '/kaggle/input/diabetic-retinopathy-dataset'\n\n# Create two lists to store paths of images and their labels\n\nimgpaths = []\nlabels =[]\n\n\n# Convert directory to list\n\ndata = os.listdir(Path_data)\n\n# Get paths and Labels of classes and images in data \n\nfor i in data:\n    classpath = os.path.join(Path_data, i)\n    imglist = os.listdir(classpath)\n    \n    for img in imglist:\n        imgpath = os.path.join(classpath, img)\n        \n        imgpaths.append(imgpath)\n        labels.append(i)\n\n\n# Convert two lists of imgpaths and their labels into series\n\nPaths = pd.Series(imgpaths, name = 'Paths')\nLabels = pd.Series(labels, name = 'Labels')\n\n# Concatenate them in one Dataframe called Tr_data\n\nDf= pd.concat([Paths, Labels], axis = 1)\nDf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3 Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## A- Split data into train, valid, test","metadata":{}},{"cell_type":"code","source":"#train, valid  and test dataframes\ntrain, testval = train_test_split(Df, test_size = 0.2, shuffle = True, random_state = 123)\nvalid, test = train_test_split(testval, test_size = 0.5, shuffle = True, random_state = 123)\n\nprint(\"Train shape: \", train.shape)\nprint(\"Valid shape: \", valid.shape)\nprint(\"Test shape: \",test.shape)\n\ntrain.Labels.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## B- Data Augmentation","metadata":{}},{"cell_type":"code","source":"batch_size = 20   # As smaller, As more data generated ....In views of data size \nimg_size = (224, 224) # standard value (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\n\n#Create generators\n\ntr_G = ImageDataGenerator(\n    zca_whitening=True,\n    rotation_range=30.,\n    fill_mode='nearest',\n    )\n\nV_G = ImageDataGenerator()\n\nt_G = ImageDataGenerator()\n\n#Generate Appropriate Data for fitting into model\n\nTrain = tr_G.flow_from_dataframe(train, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size = batch_size)\nValid = V_G.flow_from_dataframe(valid, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = True, batch_size = batch_size)\nTest = t_G.flow_from_dataframe(test, x_col = 'Paths', y_col = 'Labels', target_size = img_size, class_mode = 'categorical', color_mode = 'rgb', shuffle = False, batch_size = batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 Modelling","metadata":{}},{"cell_type":"code","source":"base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n\n# Freeze all layers in the base model\nfor layer in base_model.layers:\n    layer.trainable = True\n\n# Create your own fully connected layers on top of the model base\nx = Flatten()(base_model.output)\nx = Dense(64, activation='relu')(x) # Number of Nodes\noutput = Dense(5, activation='softmax')(x)\n\n# Create a new model by combining the base model and custom layers\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A - Training phase","metadata":{}},{"cell_type":"code","source":"epochs = 20\nhistory = model.fit(x= Train, epochs= epochs, verbose= 1, validation_data= Valid, validation_steps= None, shuffle= False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## B - Evaluation ","metadata":{}},{"cell_type":"code","source":"# accuracy and loss of Train\n\ntr_acc = history.history['acc']\ntr_loss = history.history['loss']\n\n\n# accuracy and loss or Valid\\\n\nv_acc = history.history['val_acc']\nv_loss = history.history['val_loss']\n\n\n# highest value of v_acc by getting its index\n\nindex_acc = np.argmax(v_acc)\nhigh_Vacc = v_acc[index_acc]\n\n\n# lowest value of v_loss by getting index\n\nindex_loss = np.argmin(v_loss)\nlow_Vloss = v_loss[index_loss]\n\n\n# n. of epochs based on length of tr_acc values\n\nEpochs =[]\nfor i in range(len(tr_acc)):\n    Epochs.append (i+1)\n\n    \n# Define best epoch\n\nbest_acc = f'Best epoch ={str(index_acc +1)}'\nbest_loss = f'Best epoch ={str(index_loss+1)}'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## C- Let's Visualize it","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 8))\n\n\nplt.subplot(1,2,1)\nplt.plot(Epochs, tr_acc, \"g\", label = \"Train Accuarcy\")\nplt.plot(Epochs, v_acc, \"r\", label = \"Valid Accuarcy\")\nplt.scatter(index_acc+1, high_Vacc, s= 150, color = 'purple', label = best_acc)\n\nplt.title(\"Accuracy: Train Vs valid\")\nplt. xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig(\"Accuracy.svg\", format=\"svg\")\n\n\nplt.subplot(1,2,2)\nplt.plot(Epochs, tr_loss, \"g\", label = \"Train Loss\")\nplt.plot(Epochs, v_loss, \"r\", label = \"Valid Loss\")\nplt.scatter(index_loss+1, low_Vloss, s= 150, color = 'purple', label = best_loss)\n\nplt.title(\"Loss: Train Vs valid\")\nplt. xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig(\"Loss.svg\", format=\"svg\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Vars\nTrain_sc = model.evaluate(Train, verbose = 1)\nValid_sc = model.evaluate(Valid, verbose = 1)\nTest_sc =model.evaluate(Test, verbose = 1)\n\n#Print\nprint('Train Scores : \\n    accuracy:', Train_sc[1], '\\n      Loss: ', Train_sc[0], '\\n________________________')\nprint('Valid Scores : \\n    accuracy:', Valid_sc[1], '\\n      Loss: ', Valid_sc[0], '\\n________________________')\nprint('Test Scores : \\n    accuracy:', Test_sc[1], '\\n      Loss: ', Test_sc[0], '\\n________________________')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5 Get  predictions","metadata":{}},{"cell_type":"code","source":"predictions = model.predict_generator(Test)\ny_pred = np.argmax(predictions, axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use n. of keys of  Class indices to greate confusion matrix\nTest_cl_ind = Test.class_indices\n \n# Get Keys\nclasses = list(Test_cl_ind.keys())\n\n#CM\ncm = confusion_matrix(Test.classes, y_pred)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualise it\nplt.figure(figsize =(8, 8))\nplt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Greens)\nplt.title(\"Confusion Matrix\")\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes,rotation = 45)\nplt.yticks(tick_marks, classes)\n\nthresh = cm.max()/2\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(i, j, cm[i, j], horizontalalignment = 'center', color = 'white' if cm[i,j] > thresh  else 'red')\n    \nplt.tight_layout()\nplt.xlabel('Predictions')\nplt.ylabel('Real Values')\nplt.savefig(\"CF.svg\", format=\"svg\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1 = Test.classes\ny2 = y_pred\nprint(y2)\nprint(\"Accuracy: \",accuracy_score(y1, y2))\nprint(\"Recall: \",recall_score(y1, y2, average = 'micro'))\nprint(\"Precision: \",precision_score(y1, y2, average='micro'))\nprint(\"F1_Score: \",f1_score(y1, y2, average = 'micro'))\nprint(\"Kappa Score: \",cohen_kappa_score(y1, y2, weights = 'quadratic'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6 Save model","metadata":{}},{"cell_type":"code","source":"model.save('effB4 CNN DR.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
